{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Customer Database\n",
    "**This is the first of three mandatory projects to be handed in as part of the assessment for the course 02807 Computational Tools for Data Science at Technical University of Denmark, autumn 2019.**\n",
    "\n",
    "#### Practical info\n",
    "- **The project is to be done in groups of at most 3 students**\n",
    "- **Each group has to hand in _one_ Jupyter notebook (this notebook) with their solution**\n",
    "- **The hand-in of the notebook is due 2019-10-13, 23:59 on DTU Inside**\n",
    "\n",
    "#### Your solution\n",
    "- **Your solution should be in Python**\n",
    "- **For each question you may use as many cells for your solution as you like**\n",
    "- **You should document your solution and explain the choices you've made (for example by using multiple cells and use Markdown to assist the reader of the notebook)**\n",
    "- **You should not remove the problem statements, and you should not modify the structure of the notebook**\n",
    "- **Your notebook should be runnable, i.e., clicking [>>] in Jupyter should generate the result that you want to be assessed**\n",
    "- **You are not expected to use machine learning to solve any of the exercises**\n",
    "- **You will be assessed according to correctness and readability of your code, choice of solution, choice of tools and libraries, and documentation of your solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Your team has been hired by the company X as data scientists. X makes gadgets for a wide range of industrial and commercial clients.\n",
    "\n",
    "As in-house data scientists, your teams first task, as per request from your new boss, is to optimize business operations. You have decided that a good first step would be to analyze the companys historical sales data to gain a better understanding of where profit is coming from. It may also reveal some low hanging fruit in terms of business opportunities.\n",
    "\n",
    "To get started, you have called the IT department to get access to the customer and sales transactions database. To your horror you've been told that such a database doens't exist, and the only record of sales transactions is kept by John from finance in an Excel spreadsheet. So you've emailed John asking for a CSV dump of the spreadsheet...\n",
    "\n",
    "In this project you need to clean the data you got from John, enrich it with further data, prepare a database for the data, and do some data analysis. The project is comprised of five parts. They are intended to be solved in the order they appear, but it is highly recommended that you read through all of them and devise an overall strategy before you start implementing anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Cleaning the data\n",
    "John has emailed you the following link to the CSV dump you requested.\n",
    "\n",
    "- [transactions.csv](https://raw.githubusercontent.com/patrickcording/02807-comp-tools/master/docker/work/data/transactions.csv)\n",
    "\n",
    "It seems as though he has been a bit sloppy when keeping the records. \n",
    "\n",
    "In this part you should:\n",
    "- Explain what the data is\n",
    "- Clean it to prepare it for inserting into a database and doing data analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Intro\n",
    "In the following sections we go through each column/feature in the data and provide a feature description. Right after each description in a markdown cell we have the corresponding code cell with python to clean the data in the column described.\n",
    "The columns 'company', 'country' and 'city' are described and cleaned together.\n",
    "\n",
    "We thus iterate over all data multiple times, which is obviously slower than fixing everything in one iteration.\n",
    "\n",
    "We do this to provide an easy to read implementation. We do not consider the performance of a clean up script important, since it only has to be run once. If it had to be run many times and someone was waiting for the answer each time, we would have selected another approach.\n",
    "\n",
    "Before doing the feature description we import data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"transactions.csv\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part\n",
    "This seems to be a partnumber (string). To investigate the purity and nature of the data \n",
    "the part number was analysed using command line. The following command revealed best results:\n",
    "cut -d , -f 1 transactions.csv | sort | uniq -c\n",
    "It showed that majority of part numbers were used around 200 times\n",
    "10 records countained an empty part number\n",
    "the \"real part numbers\" had format: \n",
    "4 or 5 digits followed by '-' followed by 3 or 4 digits\n",
    "In total there are 100 different part numbers (excluding the empty part number)\n",
    "We cannot correct part number data to include correct part number, since we cannot infer part number from remaining columns. Therefore, no cleanup is made for the 'Part' feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company\n",
    "This seems to be a company name (string)\n",
    "To analyse the purity/nature following command was used:\n",
    "cut -d , -f 2 transactions.csv | sort | uniq -c\n",
    "36 different companies exist\n",
    "Most appearing company is 'Thoughtmix' which appears 2795 times (raw data)\n",
    "However 'Thoughtmix' also appears as 'Thoughtmixz' (this is assumed to be spelling error)\n",
    "Apart from spelling errors there seem to be 3 outliers:\n",
    "'-', 'a', 'aa' which all appear a single time\n",
    "\n",
    "### Country\n",
    "This seems to be the country, where the company is placed (string)\n",
    "To analyse the purity/nature following command was used:\n",
    "cut -d , -f 3 transactions.csv | sort | uniq -c\n",
    "15 different countries were listed\n",
    "The 'empty' country appeared 2171 times so it seems like John forgot to not the real company multiple times\n",
    "Some as for company names some country names are listed wrongly:\n",
    "e.g. 'US' is used once in stead of 'United States'\n",
    "e.g. 'Tyskland' is used once in stead of 'Germany'\n",
    "\n",
    "### City \n",
    "This seems to be the city, where the company is placed (string)\n",
    "To analyse the purity/nature following command was used:\n",
    "cut -d , -f 4 transactions.csv | sort | uniq -c\n",
    "This gives 32 different cities\n",
    "The whitespace sicty appear 33 times\n",
    "Seems like there are few/no spelling mistakes\n",
    "However, some values appear only once, so maybe the city was typed wrongly\n",
    "for some companied/contries\n",
    "\n",
    "### Fixing Issues\n",
    "To fix issues for column: 'company', 'country', 'city' (including many empty countries), following command is useful:\n",
    "cut -d , -f 2-4 transactions.csv | sort | uniq -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##iterate over all rows to set:\n",
    "    #Company names for companies registered with typos (very few of these)\n",
    "    #Country and and City for records where these are different from the majority\n",
    "\n",
    "#The majority has been found using the description above and all other records of that company are set to same country/city\n",
    "\n",
    "#Only exception to this is company 'Flipstorm' which has two cities registered as costumers\n",
    "    #For Flipstorm this was easy to fix as the two cities are in different countries\n",
    "    #And all records for Flipstorm lists a country. So the country was used to assign a city\n",
    "    \n",
    "for index, row in df.iterrows():\n",
    "    if (row['company'] == 'Avaveo' and row['country']!='France'):\n",
    "        row['country'] = 'France'\n",
    "    \n",
    "    elif (row['company'] == 'Brainsphere'):\n",
    "        if(row['country']!= 'Portugal'):\n",
    "            row['country'] = 'Portugal'\n",
    "        if(row['city']!='Braga'):\n",
    "            row['city'] = 'Braga'\n",
    "            \n",
    "    elif(row['company']== 'Bubblemix' and row['country'] !='Japan'):\n",
    "        row['country'] = 'Japan'\n",
    "        \n",
    "    elif(row['company']=='Buzzbean' and row['country'] != 'Germany'):\n",
    "        row['country'] = 'Germany'\n",
    "        \n",
    "    elif(row['company']=='Chatterbridge' and row['country']!= 'Spain'):\n",
    "        row['country']='Spain'\n",
    "        \n",
    "    elif(row['company']=='Eimbee' and row['country']!= 'France'):\n",
    "        row['country']='France'\n",
    "\n",
    "    elif(row['company']=='Flipstorm'):\n",
    "        if(row['city'] == 'Athens' and row['country'] != 'Greece'):\n",
    "            row['country']='Greece'\n",
    "        if(row['city'] == 'Nanterre' and row['country'] != 'France'):\n",
    "            row['country']='France'\n",
    "    \n",
    "    elif(row['company']=='Gabcube' and row['country']!= 'Portugal'):\n",
    "        row['country']='Portugal'    \n",
    "    \n",
    "    elif(row['company']=='Gabtune' and row['country']!= 'France'):\n",
    "        row['country']='France'\n",
    "\n",
    "    elif(row['company']=='Gevee' and row['country']!= 'France'):\n",
    "        row['country']='France'\n",
    "        \n",
    "    elif(row['company']=='Innojam' and row['country']!= 'Netherlands'):\n",
    "        row['country']='Netherlands'\n",
    "        \n",
    "    elif(row['company']=='Kanoodle'):\n",
    "        if(row['country']!= 'Netherlands'):\n",
    "            row['country']='Netherlands'\n",
    "        if(row['city']!='Niihama'):\n",
    "            row['city']='Niihama'\n",
    "     \n",
    "    elif(row['company'] == 'Laj0'):\n",
    "        row['company'] = 'Lajo'\n",
    "        \n",
    "    elif(row['company']=='Lajo' and row['country']!= 'Greece'):\n",
    "        row['country']='Greece'\n",
    "        \n",
    "    elif(row['company'] == 'Ntagz'):\n",
    "        row['company'] = 'Ntags'\n",
    "        \n",
    "    elif(row['company']=='Ntags'):\n",
    "        if(row['country']!= 'Portugal'):\n",
    "            row['country']='Portugal'\n",
    "        if(row['city']!='Lisbon'):\n",
    "            row['city']='Lisbon'\n",
    "            \n",
    "    elif(row['company']=='Realpoint' and row['country']!= 'Portugal'):\n",
    "        row['country']='Portugal'\n",
    "        \n",
    "    elif(row['company']=='Thycero' and row['country']!= 'France'):\n",
    "        row['country']='France'\n",
    "        \n",
    "    elif(row['company']=='Riffpath' and row['country']!= 'Greece'):\n",
    "        row['country']='Greece'\n",
    "        \n",
    "    elif(row['company']=='Roodel' and row['country']!= 'Portugal'):\n",
    "        row['country']='Portugal'\n",
    "        \n",
    "    elif(row['company']=='Shufflebeat'):\n",
    "        if(row['country']!= 'Portugal'):\n",
    "            row['country']='Portugal'\n",
    "        if(row['city']!='Porto'):\n",
    "            row['city']='Porto'\n",
    "            \n",
    "    elif(row['company']=='Tagtune' and row['country']!= 'Switzerland'):\n",
    "        row['country']='Switzerland'\n",
    "        \n",
    "    elif(row['company']=='Teklist'):\n",
    "        if(row['country']!= 'Netherlands'):\n",
    "            row['country']='Netherlands'\n",
    "        if(row['city']!='Arnhem'):\n",
    "            row['city']='Arnhem'\n",
    "            \n",
    "    elif(row['company'] == 'Thoughtmixz'):\n",
    "        row['company'] = 'Thoughtmix'\n",
    "        \n",
    "    elif(row['company']=='Thoughtmix'):\n",
    "        if(row['country']!= 'Portugal'):\n",
    "            row['country']='Portugal'\n",
    "        if(row['city']!='Amadora'):\n",
    "            row['city']='Amadora'\n",
    "            \n",
    "    elif(row['company']=='Twitterbeat'):\n",
    "        if(row['country']!= 'France'):\n",
    "            row['country']='France'\n",
    "        if(row['city']!='Annecy'):\n",
    "            row['city']='Annecy'\n",
    "            \n",
    "    elif(row['company']=='Voomm' and row['country']!= 'France'):\n",
    "        row['country']='France'\n",
    "        \n",
    "    elif(row['company']=='Wordify'):\n",
    "        if(row['country']!= 'United States'):\n",
    "            row['country']='United States'\n",
    "        if(row['city']!='New York'):\n",
    "            row['city']='New York'\n",
    "            \n",
    "    elif(row['company']=='Yozio'):\n",
    "        if(row['country']!= 'Greece'):\n",
    "            row['country']='Greece'\n",
    "        if(row['city']!='Patras'):\n",
    "            row['city']='Patras'\n",
    "            \n",
    "    elif(row['company']=='Zoonder'):\n",
    "        if(row['country']!= 'United States'):\n",
    "            row['country']= 'United States'\n",
    "        if(row['city']!='Boston'):\n",
    "            row['city']='Boston'\n",
    "            \n",
    "    elif(row['company'] == 'Zooxo.'):\n",
    "        row['company'] = 'Zooxo'        \n",
    "            \n",
    "    elif(row['company']=='Zooxo'):\n",
    "        if(row['country']!= 'United Kingdom'):\n",
    "            row['country']= 'United Kingdom'\n",
    "        if(row['city']!='London'):\n",
    "            row['city']='London'\n",
    "    \n",
    "    #We set company for typo'ed companies based on their location (NY and Boston)\n",
    "    #Since there is only one company we sell to in new york and one company in Boston\n",
    "    elif(row['company'] == ' -'):\n",
    "        row['company'] = 'Zoonder'\n",
    "        \n",
    "    elif(row['company'] == ' a'):\n",
    "        row['company'] = 'Wordify'\n",
    "        \n",
    "    elif(row['company'] == 'aa'):\n",
    "        row['company'] = 'Wordify'\n",
    "        \n",
    "##Following was used for testing\n",
    "#i=0            \n",
    "#for index, row in df.iterrows():\n",
    "#    if (row['company'] == 'Zoonder' and row['country']=='United States'):\n",
    "#        i+=1\n",
    "#print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price\n",
    "\n",
    "#negative values, e.g.  $-153.91\n",
    "#values with $ first, e.g. $1.0\n",
    "#empty value \n",
    "\n",
    "#cut -d , -f 5 transactions.csv | sort | uniq -c| head\n",
    "\n",
    "#inspecting what they can start with: \n",
    "#cut -d , -f 5 transactions.csv | cut -c 1-1 | sort | uniq -c \n",
    "#Normal values: $, 1-9, Pund, Yen?\n",
    "#Odd values: empty: 1, '-' (negative values): 61, 'n': 3, 'v': 2\n",
    "\n",
    "        \n",
    "#cut -d , -f 5 transactions.csv | grep n\n",
    "#shows three entries have value 'na'\n",
    "\n",
    "#cut -d , -f 5 transactions.csv | grep v\n",
    "#shows two entries have value 'void'\n",
    "\n",
    "#cut -d , -f 5 transactions.csv | grep - | head\n",
    "#e.g.: '-181.47€', '£-91.3'\n",
    "\n",
    "#using cmd: cut -d , -f 5 transactions.csv | grep € | cut -c 1-1 | sort | uniq\n",
    "#we can see that lines with € generally end with € and doesn't have other monetary value at start\n",
    "#Thus, since this is only monetary value which seems to be at the end, it seems fair to assume\n",
    "#That no line contains two different monetary declarations (e.g. $12.12€)\n",
    "\n",
    "#cut -d , -f 5 transactions.csv | grep € | grep -\n",
    "#shows one line has value '-'\n",
    "\n",
    "#=> empty value, '-' value, 'n' values, 'v' values.\n",
    "#=> negative values treated as positive values\n",
    "#=> positive values: extract monetary value from first or last char\n",
    "\n",
    "#in python script do something like\n",
    "#if starts with $ - dollar\n",
    "#else if starts with € - euro\n",
    "#else: Alert(has no monetary value) - to check if any lines have zero monetary declaration\n",
    "#also check for double monetary declaration? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if (row['price'] == 'na' or row['price'] == '-' or row['price'] == 'void' or not isinstance(row['price'],str)):\n",
    "        row['price']=0 \n",
    "    else:\n",
    "        contain_currency = 0    \n",
    "        if ('€' in row['price']):\n",
    "            contain_currency = 1\n",
    "        if ('$' in row['price']):\n",
    "            contain_currency = 1\n",
    "        if ('£' in row['price']):\n",
    "            contain_currency = 1\n",
    "        if ('¥' in row['price']):\n",
    "            contain_currency = 1\n",
    "        if(contain_currency==0):\n",
    "            row['price']=row['price']+'€' #assume default value is € if none is declared - probably get this from most used value from company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date\n",
    "This seems to be the date for the transaction, consisting of a date and a specific time\n",
    "\n",
    "cut -d , -f 6 transactions.csv | cut -d ' ' -f 1 | sort | uniq -c | head\n",
    "7 10/04/2017\n",
    "19 2016-01-02\n",
    "same query with tail only reveals regular date formatted values:\n",
    "14 2018-12-31\n",
    "1 2019-02-21\n",
    "1 2019-05-14\n",
    "1 date\n",
    "\n",
    "Inspect time parameter: \n",
    "cut -d , -f 6 transactions.csv | cut -d ' ' -f 2 | sort | uniq -c | head\n",
    "9 \n",
    "2 00:00:05\n",
    "2 00:00:06\n",
    "Same query with tail shows regular formatting (no value larger than 23:59:59)\n",
    "\n",
    "Any with dates in middle?\n",
    "\n",
    "using query: \n",
    "cut -d , -f 6 transactions.csv | cut -d ' ' -f 1 | cut -d '-' -f 2 | sort | uniq -c \n",
    "It can be seen that all rows (but ones with wrong format) have a value in second date format, which is 12 or below. Thus the second column defined the month and the date format is thus: 'yyyy:mm:dd'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "#Some have spaces after them (07,08,10,17,21)\n",
    "#and there are two dates with 32\n",
    "#some months with 31, which should not have?\n",
    "#2016-06-32\n",
    "k=0\n",
    "for index, row in df.iterrows():\n",
    "    #one date has wrong format (multiple occurences of this day exist)\n",
    "    #we assume this date has format (dd:mm:yyyy) and translates it to regular format (yyyy:mm:dd)\n",
    "    #although it could also have format mm:dd:yyyy (seems less likely)\n",
    "    if (row['date'].startswith('10/04/2017')):\n",
    "        row['date']='2017-04-10'\n",
    "    if (row['date'].startswith('2016-06-32 07:22:28')):\n",
    "        row['date']='2016-06-30 07:22:28'\n",
    "    if (row['date'].startswith('2016-06-32 08:08:48')):\n",
    "        row['date']='2016-06-30 08:08:48'\n",
    "\n",
    "    try: #try read lines with formay yyyy-mm-dd and convert them to format yyyy-mm-dd HH:MM:SS\n",
    "        #some dates without H:M:S have trailing whitespace, so we strip here\n",
    "        date = row['date'].strip() #\"strip for mig\"\n",
    "        t = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "        row['date']=t.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    except: \n",
    "        try: #This let us print out an error message in case there exist a timestamp not matching desired format\n",
    "            t = datetime.strptime(row['date'], \"%Y-%m-%d %H:%M:%S\")\n",
    "        except:\n",
    "            print('Error converting time for transaction ' +  row['company'] + \" \" + row['date']) #used for debugging\n",
    "    k+=1\n",
    "# used for debugging       \n",
    "#    if (k%1000==0):\n",
    "#       print(t)\n",
    "#        print(type(t))\n",
    "#        newdate=t+timedelta(1)\n",
    "#        print (newdate.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "part       object\n",
       "company    object\n",
       "country    object\n",
       "city       object\n",
       "price      object\n",
       "date       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.astype({'company':'str'})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Enriching the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common task for a data scientists is to combine or enrich data from internal sources with data available from external sources. The purpose of this can be either to fix issues with the data or to make it easier to derive insights from the data.\n",
    "\n",
    "In this part you should enrich your data with data from at least one external source. You may look to part 4 for some  inspiration as to what is required. Your solution should be automated, i.e., you can not ask the reader of your notebook to download any data manually. You should argue why and what you expect to achieve by the enrichments you are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decribe required enrichment\n",
    "In section 4 we have to compare the profit between companies. To do so, we should calculate all prices to use same currency, such that price of every transaction can be compared with the price of any other transaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "\n",
    "\n",
    "#Date for first value in csv file: 2016-01-02\n",
    "#Date for last value in csv file: \n",
    "\n",
    "#invoke rest api for exchange rates\n",
    "resp = req.get(\"https://api.exchangeratesapi.io/history?start_at=2016-01-02&end_at=2019-05-14&symbols=USD,GBP,JPY\")\n",
    "\n",
    "# Read it as json\n",
    "json = resp.json()\n",
    "rate = json['rates']\n",
    "\n",
    "# make a data frame (cdf: currency data frame)\n",
    "cdf = pd.DataFrame.from_dict(rate)\n",
    "\n",
    "\n",
    "def get_eur_exchange_ratio(currency, date):\n",
    "    #print('mycurr ' + currency)\n",
    "    date_time_obj = datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    i=0\n",
    "    exchange_ratio = 0\n",
    "    while (exchange_ratio == 0):    \n",
    "        try:\n",
    "            exchange_ratio = cdf.at[currency,date_time_obj.strftime('%Y-%m-%d')]\n",
    "        except: \n",
    "            date_time_obj = date_time_obj + timedelta(1); #try next day\n",
    "            i+=1\n",
    "            if(i>20):\n",
    "                print(\"Error displaying currency: \")\n",
    "                print(currency)\n",
    "                print(\"date: \" + date)\n",
    "                print(date_time_obj)\n",
    "                return 0\n",
    "                \n",
    "    return exchange_ratio\n",
    "#        try:\n",
    "#            next_day = \n",
    "##            next_day_val = cdf.at[currency,next_day.]\n",
    " #           return next_day_val\n",
    " #       except:\n",
    " #           try:\n",
    " #               two_days_from_day = date_time_obj + timedelta(2);\n",
    " #               two_days_from_day_val = cdf.at[currency,two_days_from_day.strftime('%Y-%m-%d')]\n",
    " #               return two_days_from_day_val\n",
    " #           except:\n",
    " #               try:\n",
    " #                   day_before = date_time_obj - timedelta(1)\n",
    " #                   day_before_val = cdf.at[currency,day_before.strftime('%Y-%m-%d')]\n",
    " #                   return day_before_val \n",
    " #               except:\n",
    " #                   print(\"Error displaying currency: \" + currency + \" at date: \" + date)\n",
    " #                   print(next_day, next_day_val)\n",
    " #                   print(two_days_from_day)\n",
    " #                   print(two_days_from_day_val)\n",
    " #                   print(day_before)\n",
    " #                   print(day_before_val)\n",
    "                \n",
    "\n",
    "def get_eur_price(currency,original_value,date): \n",
    "    #print('currency: ' + currency + ' val ' + str(original_value))\n",
    "    conversion_rate = get_eur_exchange_ratio(currency, date) #get conversion rate from data frame \n",
    "    #print(conversion_rate)\n",
    "    try: \n",
    "        eur_value = original_value/conversion_rate #apply conversion rate to get eur/cent value\n",
    "    except:\n",
    "        print('conv: ' + str(conversion_rate) + ' orig: ' + str(original_value))\n",
    "    #since currency is already declared in cents (as int),\n",
    "    #We round to ensure we get to nearest full 'cent'\n",
    "    return int(round(eur_value))\n",
    "\n",
    "#This function gives string value, that currency is listed as in data frame for exchange rates\n",
    "#e.g. € is listed as 'EUR'\n",
    "def get_currency_string_from_price_string(price_string):\n",
    "    if('€' in price_string) :\n",
    "        return 'EUR'\n",
    "    elif('$' in price_string) : \n",
    "        return 'USD'\n",
    "    elif('£' in price_string): \n",
    "        return 'GBP'\n",
    "    elif('¥' in price_string):     #ASSUMED THAT ¥ is Japanese Yen \n",
    "        return 'JPY'\n",
    "\n",
    "#convert from 'euro.cents' format to two last digits in int declaring cents and any digit before than declaring euros\n",
    "#e.g. '2732' is interpreted as 27 euro and 32 cents\n",
    "def get_price_as_int(price):\n",
    "    #print('_: ' + price)\n",
    "    pricestrings = price.split('.') #divide between euros and cents\n",
    "    priceint = int(pricestrings[0]) * 100 #multiply euro value by 100 \n",
    "    #print('1: ' + str(priceint))\n",
    "    if (pricestrings[0].startswith('-')): \n",
    "        priceint -= int(pricestrings[1]) #if eur value is negative we need to subtract the cents from current value\n",
    "    else:\n",
    "        priceint += int(pricestrings[1])\n",
    "    #print('2: ' + str(priceint))\n",
    "    return priceint\n",
    "   \n",
    "\n",
    "lol = get_eur_exchange_ratio('GBP', '2016-03-26 16:23:09')\n",
    "    \n",
    "    \n",
    "translation_table = dict.fromkeys(map(ord, '$€£¥'), None)\n",
    "l=0\n",
    "for index, row in df.iterrows():\n",
    "    if (row['price']==0):\n",
    "        continue\n",
    "    try:\n",
    "        currency_string = get_currency_string_from_price_string(row['price'])\n",
    "    except:\n",
    "        print(row)\n",
    "        \n",
    "    price_without_currency = row['price'].translate(translation_table) #Remove currency symbol from price\n",
    "    \n",
    "    try: \n",
    "        price_int = get_price_as_int(price_without_currency)\n",
    "    except:\n",
    "        print(row)\n",
    "\n",
    "    if(currency_string == 'EUR'):\n",
    "        eur_price = price_int #if already in EUR currency , we just use value right away\n",
    "    else:\n",
    "        #print(row['price'])\n",
    "        #print(currency_string)\n",
    "        #print(price_without_currency)\n",
    "        #print(price_int)\n",
    "        try: \n",
    "            eur_price = get_eur_price(currency_string, price_int, row['date']) #Calculate price in EUR\n",
    "        except:\n",
    "            print(row)\n",
    "        #print(eur_price)\n",
    "    row['price'] = eur_price\n",
    "    l+=1\n",
    "        \n",
    "\n",
    "#print('usd: ' + str(192) + ' 2018-01-09 00:00:00' )\n",
    "#print(str(get_eur_price('USD',192,'2018-01-09 00:00:00')))\n",
    "\n",
    "\n",
    "#cadtoeu = cdf.at['USD','2018-01-09']\n",
    "#print('cad to eu: ' + str(cadtoeu))\n",
    "#eur = 192/cadtoeu\n",
    "#print('eur: ' + str(eur))\n",
    "\n",
    "#print('usd: ' + str(192) + ' 2016-01-09 00:00:00')\n",
    "#print(str(get_eur_price('USD',192,'2016-01-09 00:00:00')))\n",
    "#print(str(geteurvalue('USD',192,'2018-01-09')))\n",
    "#usdtoeu = cdf.at['USD','2016-01-11']\n",
    "#print('USD to eu: ' + str(usdtoeu))\n",
    "\n",
    "#2016-01-02\n",
    "#print(cdf)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #one date has wrong format (year in end)\n",
    "    #we assume this date has format (dd:mm:yyyy) and translates it to regular format (yyyy:mm:dd)\n",
    "    #if (row['date'].startswith('10/04/2017')):\n",
    "     #   row['date']='2017/04/10'\n",
    "\n",
    "\n",
    "#Get conversion from "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Creating a database\n",
    "Storing data in a relational database has the advantages that it is persistent, fast to query, and it will be easier access for other employees at Weyland-Yutani.\n",
    "\n",
    "In this part you should:\n",
    "- Create a database and table(s) for the data\n",
    "- Insert data into the tables\n",
    "\n",
    "You may use SQLite locally to do this. You should argue why you choose to store your data the way you do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "#Connect to the database and create tables\n",
    "conn = sqlite3.connect('weylandYutani.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('CREATE TABLE IF NOT EXISTS transactions(transaction_id INTEGER PRIMARY KEY AUTOINCREMENT, part INTEGER, price INTEGER, date_time TEXT, company_name TEXT, company_country TEXT, company_city TEXT)')\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "## Import data into the table\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    part = row['part']\n",
    "    companyName = row['company']\n",
    "    companyCountry = row['country']\n",
    "    companyCity = row['city']\n",
    "    price = row['price']\n",
    "    date_time = row['date']\n",
    "    c.execute(\"INSERT INTO transactions(part, price, date_time,company_name, company_country, company_city) VALUES (?, ?, ?, ?, ?, ?)\", (part,price,date_time,companyName,companyCountry,companyCity))\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Analyzing the data\n",
    "You are now ready to analyze the data. Your goal is to gain some actionable business insights to present to your boss. \n",
    "\n",
    "In this part, you should ask some questions and try to answer them based on the data. You should write SQL queries to retrieve the data. For each question, you should state why it is relevant and what you expect to find.\n",
    "\n",
    "To get you started, you should prepare answers to the following questions. You should add more questions.\n",
    "#### Who are the most profitable clients?\n",
    "Knowing which clients that generate the most revenue for the company will assist your boss in distributing customer service ressources.\n",
    "\n",
    "#### Are there any clients for which profit is declining?\n",
    "Declining profit from a specific client may indicate that the client is disatisfied with the product. Gaining a new client is often much more work than retaining one. Early warnings about declining profit may help your boss fighting customer churn.\n",
    "\n",
    "\n",
    "Remember, you are taking this to your new boss, so think about how you present the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f435528bd68>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxc5X3v8c9PsmRZ3jeMsWxkuBSzxCyxzWLaEhKWEFruq6EXuFkgS53kUnqTpmlJcm9IaMNN0jYLUDDcwiVQAg5huU7YzW6Md2xjY4RlW7Zk2Zas3do1evqHRjCWRtKMZjnLfN+vl16eOefMzO8ZWd955jnPOcecc4iISPDleV2AiIikhwJdRCQkFOgiIiGhQBcRCQkFuohISCjQRURCwtNAN7MHzKzGzLYnsO0vzGxL9OcDM2vMRo0iIkFhXs5DN7M/AY4CDznnzkzicTcD5zjnvpyx4kREAsbTHrpz7g2gPnaZmZ1sZs+b2SYze9PMFsR56PXAo1kpUkQkIMZ4XUAc9wFfd87tMrPzgLuBS/pXmtmJwHzgFY/qExHxJV8FuplNAC4EHjez/sVjB2x2HfA751wkm7WJiPidrwKdviGgRufc2cNscx1wU5bqEREJDF9NW3TONQN7zewvAazPWf3rzexUYCrwtkclioj4ltfTFh+lL5xPNbMqM/sK8DngK2a2FdgBXB3zkOuBx5xOESkiMoin0xZFRCR9fDXkIiIio+fZTtEZM2a40tJSr15eRCSQNm3adMQ5NzPeOs8CvbS0lI0bN3r18iIigWRm+4ZapyEXEZGQUKCLiISEAl1EJCT8dqSoiEhc3d3dVFVV0dHR4XUpWVFUVERJSQkFBQUJP2bEQDezucBDwPFAL3Cfc+5XA7Yx4FfAlUAbcKNzbnMStYuIDKuqqoqJEydSWlpKzLmeQsk5R11dHVVVVcyfPz/hxyUy5NIDfNs5dxpwPnCTmZ0+YJtPA6dEf5YB9yRcgYhIAjo6Opg+fXrowxzAzJg+fXrS30ZGDHTn3MH+3rZzrgXYCcwZsNnV9F2kwjnn1gJTzGx2UpWIiIwgF8K832jamtROUTMrBc4B1g1YNQeojLlfxeDQz5iO7ghPbKpCpzEQkVyWcKBHz1X+BPDN6FkRj1kd5yGD0tXMlpnZRjPbWFtbm1ylw7j92Z18+/GtvLnrSNqeU0RktH7wgx+watWqrL9uQrNczKyAvjB/xDn3ZJxNqoC5MfdLgOqBGznn7qPvikQsWrQobd3pmuZOAFo7e9L1lCIioxKJRLjttts8ee0Re+jRGSz3Azudcz8fYrOVwBej5y8/H2hyzh1MY50iIp6rqKhgwYIF3HDDDSxcuJBrrrmGtrY2SktLue2227jooot4/PHHufHGG/nd734HwIYNG7jwwgs566yzWLJkCS0tLUQiEb7zne+wePFiFi5cyL333puW+hLpoS8FvgC8a2Zbosu+B8wDcM4tB56lb8piOX3TFr+UlupEROL40e938F71wJHf1Jx+wiRu/bMzRtyurKyM+++/n6VLl/LlL3+Zu+++G+ibN7569WoAnn/+eQC6urq49tprWbFiBYsXL6a5uZlx48Zx//33M3nyZDZs2EBnZydLly7lsssuS2qKYjwjBrpzbjXxx8hjt3HosnAikgPmzp3L0qVLAfj85z/PHXfcAcC11147aNuysjJmz57N4sWLAZg0aRIAL774Itu2bfuwF9/U1MSuXbsyH+giIn6TSE86UwZOJ+y/P378+EHbOufiTj90znHnnXdy+eWXp7U2nctFRCQJ+/fv5+23+y5r/Oijj3LRRRcNue2CBQuorq5mw4YNALS0tNDT08Pll1/OPffcQ3d3NwAffPABra2tKdemQBcRScJpp53Gr3/9axYuXEh9fT3f+MY3hty2sLCQFStWcPPNN3PWWWdx6aWX0tHRwVe/+lVOP/10zj33XM4880y+9rWv0dOT+iw9DbmIiCQhLy+P5cuXH7OsoqLimPsPPvjgh7cXL17M2rVrBz3P7bffzu23357e2tL6bB7TcaIikstCEeg5dHoHEfFQaWkp27dv97qMIYUi0EUkN+TS+ZpG01YFuogEQlFREXV1dTkR6v3nQy8qKkrqcdopKiKBUFJSQlVVFek8sZ+f9V+xKBkKdBEJhIKCgpSPpAw7DbmIiISEAj3gnnqnivV7670uQ0R8IFSBHm9fySPr9rFmd3gvfPGtFVv5b/e+7XUZIuIDoRhDH24e+vef6pszWvGTz2SpGhERb4Sqhy4ikssU6CIiIaFAFxEJCQW6iEhIKNBFREJCgS4iEhIKdBGRkAhVoDtd4kJEclgoAt3QFS5EREIR6CIiokAXEQkNBbqISEgo0EVEQkKBLiISEgp0EZGQUKCLiIREqAI93hWLRERyRTgCXccViYiEJNBFRESBLiISFgp0EZGQUKCLiISEAl1EJCQU6CIiITFioJvZA2ZWY2bbh1h/sZk1mdmW6M8P0l+miIiMJJEe+oPAFSNs86Zz7uzoz22plzU6qRxXtOtwCy+9dzhttYiIZNuIge6cewOoz0Ito5aO44ou/cUb/NVDG0fcrrWzJw2vJiKSfukaQ7/AzLaa2XNmdsZQG5nZMjPbaGYba2tr0/TS2bNpXz1n3PoCr7yvnryI+E86An0zcKJz7izgTuDpoTZ0zt3nnFvknFs0c+bMNLx0dm3e1wjAmvI6jysRERks5UB3zjU7545Gbz8LFJjZjJQrExGRpKQc6GZ2vJlZ9PaS6HOqCysikmVjRtrAzB4FLgZmmFkVcCtQAOCcWw5cA3zDzHqAduA653QiWxGRbBsx0J1z14+w/i7grrRVJCIioxKqI0X99MXAOcfrH9QS6fVPTSISbqEI9OgQvq+8vLOGGx5Yz31v7PG6FBHJEaEIdD861NwBQGVDm8eViEiuUKCPggZRRMSPFOhJ8OHIjojIhxToIiIh4ftAb+vq4cnNVb6awSIi4kcjzkP32m2/f4/HNlRywpRxnH/SdK/LERHxLd/30A9HZ4u0dQXrtLX6PiEi2eb7QA867UcVkWwJRaArNNPjhyt3sOTHq7wuQ0RGKRSBLsdat6eO0lueobI+uYOaHlxTQU1LZ9x13ZFePvfva9lY4euLV4nkNAX6KPh9ws2KjZUArNubvvCtamjnrfI6/u7xrWl7ThFJLwW6iEhIKNAD4uG1+6g7Gn84REQEAhboh5s7eGbbQa/LSEyK4zKRXvfhwVTvH2rmfz+9nW+u2JKOykQkpAIV6Nf/37Xc9JvNdHRHvC4lYaM5/0tNcwcnf+9Z/mPtPgC6enoBaGzrTmdpIhIygQr0Aw3tXpeQFfujs1Oe3lLtcSUiEiSBCvSR+H32SaKWv77b6xJEJIBCEehhO63tqp01XpcwpJB8ZoqEUigCPVG7a49m7Rqfd71aDkBDazjGvdP5mdneFaG6MTeGz0SyKZCBPpqhlYojrXzyX1/nX14sG3a79q4IX3xgPXtqj46yuj6Hm/umGD7zbkBm5SShozvCu1VNcdc55yi95Rn+5YWh3+cbHljPhT95JVPlieSsQAV6KkMr/Ye0j3To+lvlR3jjg1r+8Q/vDbmNy4GBh+aObpqGmFVzyxPb+LO7VlPT0jFoXf8XoLtfKx/yudfr9AEiGeH786F75dWy2kHLLGyD9cNY+MMXAaj4yWcGrdtS2QhAa2cEJma1LBEZRqB66LlGV2kSkWQEMtBTGfLwKiN7Ir3c+P/Ws2lfgzcFiEjoBSrQLTrX4sE1FUk/9lcvf5DmapJzoLGd18pq+ZYO3xeRDAlUoPf72fPxZ1AM13N/q7wu6dfpP/RePqJRIBH/CmSgD5TKrsruSC+tnfGvV/q/nt6ewjOnjx9CNIf2B4sEVmhnuazYsJ/qxsHT6gZm4xfuX8faPR9No/M6uNq7hj7xmNe1iYi/hTbQ/+GJdxPaLjbM/aChrcvrEgJ1NksR+Uighlz80kP1wxBIJpXXpHaUrIh4IzCBnq0QHe51fPJ5IiISl+8DPdtHZ/Ym8MkxmmmToxHyLwIikma+D/TRiHeOkX46+lJEwipUgd6f1Ut+/LK3hYzSq2U1fOrnr2f8dSrr2ziS4QtO62NTJPsCFehDDb6kc1jGyxNwff/Jd2kbZtpiuvzxz15l0T+tGtVjHY5DzX3fgHYebB60XvsZRLwzYqCb2QNmVmNmcY+ysT53mFm5mW0zs3PTX+bQrrvvbZ5658CoHrtU5+ROmMVEdUd330WrH377oyNptx9oYtM+f00BFck1ifTQHwSuGGb9p4FToj/LgHtSLytxyc4jjx0KOBDnqjlhHWPv7XXsTvGiHcO56s7VfPaetzP2/CIyshEPLHLOvWFmpcNscjXwkOtLwrVmNsXMZjvnwnepngz67D1rqG4aemfuaP12YyXFhflUNbTzk+fe5w83X5T210jGS+8d9vT1RcIsHUeKzgEqY+5XRZcNCnQzW0ZfL5558+al4aXDI12n1V1TfoQnN380BPX3v9sGwGWnzwKgqiF91/JM9jTGzR3d/NVDGz+839jWxZTiwrTVI5Lr0rFTNN5+sLh/6c65+5xzi5xzi2bOnJn8C3l8qGi8l69p7uDyX7yRkYse94/+JBObq3bWpL2OZHzvqaFPuRCJHNuSs297KdPliOSUdAR6FTA35n4JUJ2G582IZIfIN+1r4Jerhj6X+m83VlJ2uIVH1mX+VLt+m0ES7718bEPl4IUikhXpCPSVwBejs13OB5qCPH4+8FvAZ+9Zwy9X7crIay3+8SqWxQxBZENFXWtKj+/tTVMhIpJ2I46hm9mjwMXADDOrAm4FCgCcc8uBZ4ErgXKgDfhSpoodSTomqGRzlkttSycvJrCTMJ017atrS+nx8WYGiYg/JDLL5foR1jvgprRVJEOL+fbw1DtV5GVhn0JVQxslU4t9c6ZLERlaoM6Hrkz5yLdWbI27fOTgTa63f9FPX+WN73xCgS4SAIE69D8dvD5sKNmpfolq7uimqa17yPX9gTya0ZvhTnYmIv4RqB56Nix7eFNKj99X10pLx+BrlFqGv1+c/aMX6XXwlYvmZ/R1Ynn94Sgix1Kgp9mf/vNraXuuZAKz12fpGtIzKIj4Ws4NuaQiHX3syvrEZ4lsrWxM+vlHqnG0QauAFvG/YAV6OhI1h5Ip3nTH0Y7hP/DW3lTLEZEMC1agiyccsGUU3xZEJLtCFei50/cevdF+QdG0RRH/C1WgZ1JNcwedPd4c955MBg8VvBmZZaNPUBFfCdQsl7QMoY/ycUtu9/46pV52ktVBF/E/9dBzjDrVIuEVmB56Dk1Oyah47+Nb5Ueoahj6pF1670WCwfeBrq/6mfe5f1837Prm9m4279csFxG/y7khl7D3NtNxVaeB79GtK3fE304DOCK+EqhA9/oSdGFQ39o54jbt3ZFj7rd2DT43DYT/w1EkaAIV6DKy+97YE3d5/2fhq2W1WaxGRLIpVIGezasN5RK9rSLBEKpAl8zQB6VIMORcoGtHXvL0jokEQ6ACXftEPaJEFwmEQAW6+ItyXsRfFOgB4PUQtoJbJBhyLtC9DsdUeDXkpJ2iIsGQc4HuFa/H/1N5fcW5SDAEKtC1T1REZGiBCvSRBKkn+dQ7VV6XMKSBQywacREJhlAFeiIyFU7JPu+3VmzNTCEx0nXum6Hm7mtsXcRfAhXofoyP7JwwLLst10nQRIIpUIGe67yKWXXERYIhUIGufqM3lOciweD7KxalW66Gk6XycTjMm9bb62hq7x79c4tI2uRcoPvB89sPel1CUoY7odmdr5Tzi1UfZLEaERlKoIZcgix2HPpvHt3iXSFp5ICXdh4adpueSC8Pr91HT6Q3O0WJ5LBw9dATGE/ZebA583WkWZB3Sj6ybj+3rtxBZ3eEz55b4nU5IqEWqB56rk+n86r9vcN8oIw0Nt8/vq5xdpHMC1cP3af21B7laGf8Cy0HgQ4gEgmGwAS63yKlurGdq+5cTX1r14jbXvKvr2ehIhHJdQkNuZjZFWZWZmblZnZLnPUXm1mTmW2J/vwgXQX6dZTlyc1VCYW5b2TobIt+/f2I5KIRe+hmlg/8G3ApUAVsMLOVzrn3Bmz6pnPuqgzUKKPUmuFhnmRGYjRqI5J5ifTQlwDlzrk9zrku4DHg6syWFZ+fOoPZ2kFZ09JByyiD+daVOz66k0SgDmzacGE80rvgp9+ZSNglMoY+B6iMuV8FnBdnuwvMbCtQDfydc27HwA3MbBmwDGDevHnJVxtj1XuHuWTBcSk9h2eSSLklP345c3WISKgk0kOPFz8D+2ybgROdc2cBdwJPx3si59x9zrlFzrlFM2fOHLS+t9fx5q7aIWdV1MWMWX/1oY08sm5fAuVLRiXxTUXj7SKZlUigVwFzY+6X0NcL/5Bzrtk5dzR6+1mgwMxmJFvMw2v38YX71/Psu8MffdivuqnjmPvDHaIuIhJ2iQT6BuAUM5tvZoXAdcDK2A3M7HiLDiqb2ZLo89YlW8y+ujYADja1J/vQrFNvMzF3v7YbgIj2iopk3Ihj6M65HjP7a+AFIB94wDm3w8y+Hl2/HLgG+IaZ9QDtwHVOR6P4SwY+gFwCT9veHQH6htN2VAfvtAsiQZLQgUXRYZRnByxbHnP7LuCuVIvp7/X+0zM7OWvuFBaXThuhrlRfcfTiHfIelhNQZep9ffht7fMQySTfnstl1c7DXpeQtEPNHSNvFDKJDj3p65pI5vkq0IM0LO3FGHqQ3h8RyT5/BXqOJFaYmhmmtogEna8C/RgZ/I7+zv6GlJ9DQcaIg+2x+xS0j1wk83wV6MkeTj/aeefNHcE9la2fOIb/nf1m/f6PtlWei2ScrwI9VdkMjaAND3lRbos+OEWyyleBHrCMlCSogy6Seb4K9Fh+D4CRLr2WK/QuiPiHvwI92XQYkPrdkV5e2JHYeWAku5wL3jCVSNB4dgm6nuGuPDxKv1i1K6GrCKVjxoWX4dQwiisl7a9vy0AlyRxY5PfvXCLB51kPfefBZh7fWHnMslSHMby8JFwycZXqh8E5//hS0o/ZVtWU2ovGoZkrIv7i6ZDLur31Q64L4rzlbFzFqNtn54tJ9EM4gL9OkcDxbMglnmwNY7y8s4bbn92Z0nOkM7yrGxM7XbAZRDIwVJUKDaWI+IengT6w1zZcRMYbA773jT2jet2H1/rrrH9f+fVGr0sQkRDw1yyXYbzss7MvpvPLREtHd4Kv6b9pIokPuagnL5Jpvgr02FGM/r//zp6+MeM1u5O+AFJgJDN6k41c7L8ohYgEi6eBHuTxVy+mLa6vqM/Ke/bT595PaDuHS+qriuahi2SWv3roPhxSyAa/tfu9g+m/VFxwP7pFgsNXgR4kqUSw3wI8FcO1ROPmItnlbaDr7x3w3xh6pgS5dpEg8G0P3e9/+9k4iCgev70vCR/677fCRULIV4Ee9J1moy0/mcdpGENEhuLxLJfgCvqHTzok89lSdqglc4WICOC3Hnq8ZTmQnEFto3PD7+CNbdf6iqHP2yMi6eGrc7nEdnvvX72XogJffd4cw6sI1rcaERmKfxMT+LdXd3tdQkYMDLbkxtDTWkrKhgtpjfeLZJevAj3ukEvWq0iQupsi4jO+CvSclVQXPWNVjIo+10T8w9tZLgO+kgcpHAJUasb47LNFJOephz5K6fzwSa6DrhgVkfh8FejxpsAFqdeei8J0XhqRoNOBRaOUzg+fZOaha+KIiAzFXz10dfZG5Lc81+9MxD98FehBkkqQpZKBQZrbPfiasUp/kUzyeJbLsfdz9c89qO0O0oeLSC7wVQ89SF/fdei/iPiNrwI9VwX5AhdBPbGYSBglFOhmdoWZlZlZuZndEme9mdkd0fXbzOzcRJ53YDYFKRy8KlXz0FPTHemlvSsyaHltSyeRXr23/dq6euiJ9B6zrCfSy5GjnR5V5C81LR2+HHK0kYoys3zgA+BSoArYAFzvnHsvZpsrgZuBK4HzgF85584b7nnHzj7Fzb7hl6lVLyKSY/b99KpNzrlF8dYl0kNfApQ75/Y457qAx4CrB2xzNfCQ67MWmGJms1OqWkREkpJIoM8BKmPuV0WXJbuNiIhkUCIXuIg3Wjxo+DuBbTCzZcAygPGzT2betGL217cBcPGpM6lp7mRC0RhOnjmeDw4fpdc55k4tZnX5EU6cXsxnPjab/fVtTC0uZENFPfWtXVTUtQLQ0d033nfLpxfw6Pr97Kvre97PnTePzfsbqWpoY1JRAfNnjCc/z5g1aSzN7T00d3TT2tnDjAljWbO7jms+XsJvN1ZyVskU2rsj/OWiEt7Z30hlfRslU8dRe7STt8rrAJgzZRynzZ5Ia2eEj584ldqWTsbkG+8famHX4RZaOnv45IJZNLZ1MaW4kKb2Lsbk5dHQ1kWeGUeOdrKodCr5eXl09/RSOCaP1eVHuODk6XR0RTj1+Ik0tndTf7SL1eVHONrZw5lzJjG1uJCm9m5OmDyOU4+fyKtlNZw6ayKTxxWweX8D48eO4c1dRz5830+dNZGywy0U5BuTigqoa+368Hl2VDfzmY/NZkd1E5v3N1I6vZiK6Hv3F+fO4f2DLfyX4ybQ3NFNnhnlNUeZMaGQgvw8CsfkcfLMCfx2YyW3fHoBz717iPcONtPU3s1/PfsE1u+t51Onz6Klo4fK+jbauiKMLchjXEE+a3bXMaloDJeefjxPbK6iZOo4Glq7KJlazPwZ49m8v4FPnjaLQ03t7K5tZXHpNPbVtVLZ0Mbi0mmcctxEAHbXHqWlo5t3DzRx5GgXsycXUVyYzx+fMpNDTR28U9nA4eZOzjhhEuefNJ1nth1kxsRCenthQtEY5k0rpiDfONjUQVtnhPUV9Xz8xKm8f7CZqxaewKqdh1lYMplJ4wooLsznQGMHp86aQG1LJ7MmFfHugSYqjrSyeP40uiO9FBXkM2VcIdMnFLKjugkzY035ERaVTiPfjL1HWikqyGPSuALqW7uYWlxIV6SXMXnGOfOmsKWykQtOms7Bpg5aOno4bfYk9h45yprddUR6HTUtnRTkG5edfjw7DzYzrjCfj584lU37GnAOTp45nq1VTRhw6RmzKMjLY/zYMWypbGD7gWYa2rpo64owf8Z4DPjv583jqXcOsKO6GYC/vfSP2HmwmfV765k6vpDZk4to64qw6MSp7K9v40BjOwCHmjro7OnljBMm0dzRTXHBGDojvZw/fxrVTR0c7ejmj2ZNZH99G2fOmczDb+/jhClFzJlaTFdPhJNnTqChrZsZEwp5eWcN48fms6O6mU+eNovqxnaKC/PZX9/GvGnFtHT0MGHsGBrbu5hUVMDHSiazu+YoC0um8FpZDXOnFXPitGL2HGmN5oCjqqGd9w+1cMYJkwAYXziGmZPGcvLMCazeVcv5J00HYE9tK8dNGsvOg83sq2ujO9LL5HEFH/4NLC6dyoaKBgA+cepM6tu6KcgzphQXsHZPPWPH5PGJBcex/UATJx83gQ176znvpOlEenvpiTi2VTUxa9JY5s8Yz966Ns6bP421e+r441NmUHboKBsq6hlfmM/lZx7Pc+8e4sKTp1M4Jo9tVU0UjMnDgLnTivn91moWHD+RcYX57IsTth9mbAJj6BcAP3TOXR69/10A59z/idnmXuA159yj0ftlwMXOuYNDPe+iRYvcxo0bh33tZJTe8gwAFT/5TNqecygX//OrVNS18cq3/5STZk7I+OuNRmNbF0+9c4AbLyxNemdzNt9LEUmOmaU0hr4BOMXM5ptZIXAdsHLANiuBL0Znu5wPNA0X5kHXE50NUZDv31mfU4oL+dLS+YGaOSQiqRlxyMU512Nmfw28AOQDDzjndpjZ16PrlwPP0jfDpRxoA76UuZK91z+9LT9PYSki/pHQRaKdc8/SF9qxy5bH3HbATektzb/+/OwTuPf1PUweV+B1KSIiH0oo0OVY/3D5Av7mklMYP1Zvn4j4h38HgX0sL88U5iLiOwp0EZGQUKCLiISEAl1EJCQU6CIiIaE9ezLIX5wzh4lF+q8hEjT6q5VBfn7t2V6XICKjEJpAf/qmpeyobvK6DBERz4Qm0M+eO4Wz507xugwREc9op6iISEgo0EVEQkKBLiISEgp0EZGQUKCLiISEAl1EJCQU6CIiIaFAFxEJCeu7epwHL2zWApR58uL+MAM44nURHsnltkNutz+X2w7paf+JzrmZ8VZ4eaRomXNukYev7ykz25ir7c/ltkNutz+X2w6Zb7+GXEREQkKBLiISEl4G+n0evrYf5HL7c7ntkNvtz+W2Q4bb79lOURERSS8NuYiIhIQCXUQkJDwJdDO7wszKzKzczG7xooZ0MLMHzKzGzLbHLJtmZi+Z2a7ov1Nj1n032uYyM7s8ZvnHzezd6Lo7zMyiy8ea2Yro8nVmVprN9g3HzOaa2atmttPMdpjZ/4wuD337zazIzNab2dZo238UXR76tscys3wze8fM/hC9nzPtN7OKaN1bzGxjdJn37XfOZfUHyAd2AycBhcBW4PRs15GmtvwJcC6wPWbZz4BbordvAX4avX16tK1jgfnR9yA/um49cAFgwHPAp6PL/wewPHr7OmCF122Oaeds4Nzo7YnAB9E2hr790TonRG8XAOuA83Oh7QPeh78FfgP8IZf+70drqgBmDFjmefu9eCMuAF6Iuf9d4Lte/4JSaE8pxwZ6GTA7ens2fQdQDWon8EL0vZgNvB+z/Hrg3thtorfH0HeEmXnd5iHeh/8PXJpr7QeKgc3AebnUdqAEeBm4hI8CPZfaX8HgQPe8/V4MucwBKmPuV0WXhcUs59xBgOi/x0WXD9XuOdHbA5cf8xjnXA/QBEzPWOWjFP06eA59PdWcaH90uGELUAO85JzLmbZH/RL4e6A3Zlkutd8BL5rZJjNbFl3mefu9OPTf4izLhbmTQ7V7uPfD9++VmU0AngC+6Zxrjg4Bxt00zrLAtt85FwHONrMpwFNmduYwm4eq7WZ2FVDjnNtkZhcn8pA4ywLb/qilzrlqMzsOeMnM3h9m26y134seehUwN+Z+CVDtQR2ZctjMZgNE/62JLh+q3VXR2wOXH/MYMxsDTAbqM1Z5ksysgL4wf46TjGsAAAFhSURBVMQ592R0cc60H8A51wi8BlxB7rR9KfDnZlYBPAZcYmb/Qe60H+dcdfTfGuApYAk+aL8Xgb4BOMXM5ptZIX0D/is9qCNTVgI3RG/fQN/Ycv/y66J7r+cDpwDro1/NWszs/Oge7i8OeEz/c10DvOKig2pei9Z6P7DTOffzmFWhb7+ZzYz2zDGzccCngPfJgbYDOOe+65wrcc6V0vf3+4pz7vPkSPvNbLyZTey/DVwGbMcP7fdoh8KV9M2K2A183+sdHCm041HgINBN3yfqV+gb53oZ2BX9d1rM9t+PtrmM6N7s6PJF0f8Qu4G7+OgI3iLgcaCcvr3hJ3nd5piaL6LvK+A2YEv058pcaD+wEHgn2vbtwA+iy0Pf9jjvxcV8tFM0J9pP3wy9rdGfHf0Z5of269B/EZGQ0JGiIiIhoUAXEQkJBbqISEgo0EVEQkKBLiISEgp0EZGQUKCLiITEfwLCv7yx6m3FnwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##The following plot shows each company and the profit that our company earned over time. \n",
    "df = pd.read_sql_query('SELECT price, date_time, company_name FROM transactions', conn)\n",
    "    #for index, row in df.iterrows():\n",
    "    #    row['price'] = row['price']*100)\n",
    "    #df.astype({'price':'float'})\n",
    "    #df.head(100)\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Performance\n",
    "Your boss is very impressed with what you have achieved in less than two weeks, and he would like to take your idea of storing the customer and sales data in a relational database to production. However, John is concerned that the solution will not scale. His experience is telling him that you will see many occurrences of the following queries.\n",
    "\n",
    "- Show all sales to company X between time $t_1$ and time $t_2$\n",
    "- Show the latest X sales in the database\n",
    "- Show total sales per company per day\n",
    "\n",
    "Show that Johns concern is not justified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is true that with increasing number of records in the database the query time will increase. However we can index the database using the index commands. We could forexample to support the queries described above, index on companies and date time. Thus the queries would be significantly faster, even with large databases. \n",
    "\n",
    "The indexes can be made on any column that the boss would want. This would speed up the queries on that given data column.\n",
    "\n",
    "Even maintaining the database would not be slower either. If the database indexing is implemented using beta-epsilon trees, we get insertions in $O(\\frac{log_B N}{\\epsilon B^{\\epsilon}})$, where B is the block size and N is the size of the data, and $\\epsilon$ is the relation between the degree of a node and the buffersize of the buffers that contain the updates. Where as if we would just use B-trees it would be $O(log_B N)$. Thus we get significantly better update times. The result is that we can actually maintain a database, while still being able to keep multiple index over the database. (See [An Introduction to Bε-trees and Write-Optimization](https://www.usenix.org/publications/login/oct15/bender)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
