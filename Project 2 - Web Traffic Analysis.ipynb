{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Web Traffic Analysis\n",
    "**This is the second of three mandatory projects to be handed in as part of the assessment for the course 02807 Computational Tools for Data Science at Technical University of Denmark, autumn 2019.**\n",
    "\n",
    "#### Practical info\n",
    "- **The project is to be done in groups of at most 3 students**\n",
    "- **Each group has to hand in _one_ Jupyter notebook (this notebook) with their solution**\n",
    "- **The hand-in of the notebook is due 2019-11-10, 23:59 on DTU Inside**\n",
    "\n",
    "#### Your solution\n",
    "- **Your solution should be in Python**\n",
    "- **For each question you may use as many cells for your solution as you like**\n",
    "- **You should document your solution and explain the choices you've made (for example by using multiple cells and use Markdown to assist the reader of the notebook)**\n",
    "- **You should not remove the problem statements**\n",
    "- **Your notebook should be runnable, i.e., clicking [>>] in Jupyter should generate the result that you want to be assessed**\n",
    "- **You are not expected to use machine learning to solve any of the exercises**\n",
    "- **You will be assessed according to correctness and readability of your code, choice of solution, choice of tools and libraries, and documentation of your solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this project your task is to analyze a stream of log entries. A log entry consists of an [IP address](https://en.wikipedia.org/wiki/IP_address) and a [domain name](https://en.wikipedia.org/wiki/Domain_name). For example, a log line may look as follows:\n",
    "\n",
    "`192.168.0.1 somedomain.dk`\n",
    "\n",
    "One log line is the result of the event that the domain name was visited by someone having the corresponding IP address. Your task is to analyze the traffic on a number of domains. Counting the number of unique IPs seen on a domain doesn't correspond to the exact number of unique visitors, but it is a good estimate.\n",
    "\n",
    "Specifically, you should answer the following questions from the stream of log entries.\n",
    "\n",
    "- How many unique IPs are there in the stream?\n",
    "- How many unique IPs are there for each domain?\n",
    "- How many times was IP X seen on domain Y? (for some X and Y provided at run time)\n",
    "\n",
    "**The answers to these questions can be approximate!**\n",
    "\n",
    "You should also try to answer one or more of the following, more advanced, questions. The answers to these should also be approximate.\n",
    "\n",
    "- How many unique IPs are there for the domains $d_1, d_2, \\ldots$?\n",
    "- How many times was IP X seen on domains $d_1, d_2, \\ldots$?\n",
    "- What are the X most frequent IPs in the stream?\n",
    "\n",
    "You should use algorithms and data structures that you've learned about in the lectures, and you should provide your own implementations of these.\n",
    "\n",
    "Furthermore, you are expected to:\n",
    "\n",
    "- Document the accuracy of your answers when using algorithms that give approximate answers\n",
    "- Argue why you are using certain parameters for your data structures\n",
    "\n",
    "This notebook is in three parts. In the first part you are given an example of how to read from the stream (which for the purpose of this project is a remote file). In the second part you should implement the algorithms and data structures that you intend to use, and in the last part you should use these for analyzing the stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the stream\n",
    "The following code reads a remote file line by line. It is wrapped in a generator to make it easier to extend. You may modify this if you want to, but your solution should remain parametrized, so that your notebook can be run without having to consume the entire file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "def stream(n):\n",
    "    i = 0\n",
    "    with urllib.request.urlopen('https://files.dtu.dk/fss/public/link/public/stream/read/traffic_2?linkToken=_DcyO-U3MjjuNzI-&itemName=traffic_2') as f:\n",
    "        for line in f:\n",
    "            element = line.rstrip().decode(\"utf-8\")\n",
    "            yield element\n",
    "            i += 1\n",
    "            if i == n:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STREAM_SIZE = 1000\n",
    "web_traffic_stream = stream(STREAM_SIZE)\n",
    "\n",
    "#for e in web_traffic_stream:\n",
    "    #print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 11, 12, 10, 10, 11, 11, 10, 13, 9, 10, 10, 10, 11, 12, 9, 12, 11, 9, 11, 11, 9, 10, 16, 10, 10, 13, 12, 13, 11, 14, 9, 10, 10, 10, 11, 13, 10, 10, 12, 14, 13, 13, 10, 12, 10, 13, 13, 12, 11, 11, 11, 11, 10, 10, 12, 12, 11, 13, 9, 11, 10, 12, 16]\n",
      "Harmonic mean: 11.006567277006798\n",
      "64\n",
      "0\n",
      "Estimate: 60474.449351526666\n"
     ]
    }
   ],
   "source": [
    "import mmh3\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "import statistics as s\n",
    "\n",
    "m = 64\n",
    "# hashes element with a seed from an arbritary large input to a 64 bit output\n",
    "def hashElement(element, seed):\n",
    "    # mmh3 64 outputs a 128 bit hash split in to two 64 bit outputs. \n",
    "    #For this purpose returning one of them will be sufficient\n",
    "    a,b = mmh3.hash64(element, seed, signed=False)\n",
    "    return a\n",
    "\n",
    "\n",
    "def addElement(element, M):\n",
    "    hashE = hashElement(eToHash, seed)\n",
    "    upperpart = hashE >> size_lower_part\n",
    "    lowerpart = hashE & ((2 ** size_lower_part) -1)\n",
    "    # p is the position of the left most bit\n",
    "    # We subtract it for 64 to get the position counting from left to right\n",
    "    p = 64 - int(math.log(lowerpart,2))\n",
    "    # j is the integer representation of the upperpart, we do not add one as python has 0 indexed \n",
    "    j = upperpart \n",
    "    # Use upper part as index in M and set it to the max of M[j] and p\n",
    "    M[j] = max(M[j],p)\n",
    "    return M\n",
    "\n",
    "# Method to build the HLL data structure\n",
    "# If true for rnd, take a random seed\n",
    "# if true for domain, hash the domain part of the element\n",
    "def buildHyperLogLog(stream, streamSize, rnd, domain, m):\n",
    "    # define size of M\n",
    "    M = [0]*m\n",
    "    # If rnd is false, use default seed\n",
    "    seed = 42\n",
    "    if(rnd):\n",
    "        seed = random.randint(0,sys.maxsize/2)\n",
    "    # Defines the size of the upper and lower part according to litterature\n",
    "    size_upper_part = math.floor(math.log(m,2))\n",
    "    size_lower_part = m - size_upper_part\n",
    "    # Add each element in the stream to the data structure\n",
    "    for e in stream:\n",
    "        eIpOrDomain = splitElement(e)\n",
    "        eToHash = eIpOrDomain[0]\n",
    "        if(domain):\n",
    "            eToHash = eIpOrDomain[1]\n",
    "        hashE = hashElement(eToHash, seed)\n",
    "        upperpart = hashE >> size_lower_part\n",
    "        lowerpart = hashE & ((2 ** size_lower_part) -1)\n",
    "        # p is the position of the left most bit\n",
    "        # We subtract it for 64 to get the position counting from left to right\n",
    "        p = 64 - int(math.log(lowerpart,2))\n",
    "        # j is the integer representation of the upperpart, we do not add one as python has 0 indexed \n",
    "        j = upperpart \n",
    "        # Use upper part as index in M and set it to the max of M[j] and p\n",
    "        M[j] = max(M[j],p)\n",
    "    return M\n",
    "\n",
    "def getHarmonicMean(dataStucture):\n",
    "    return s.harmonic_mean(dataStucture)\n",
    "\n",
    "# takes harmonic mean hm and size of array, m as input, outputs the estimate\n",
    "def getEstimate(hm, M, m):\n",
    "    #alpha is the constant adjust to correct for bias. It's value is defined on Wiki: \n",
    "    #https://en.wikipedia.org/wiki/HyperLogLog#Operations\n",
    "    alpha = 0.709\n",
    "    E = alpha * (m**2) * (sum([2**-number for number in M])**-1)\n",
    "    V = 0\n",
    "    print(m)\n",
    "    for i in range(len(M)): \n",
    "        if(M[i]==0):\n",
    "            V += 1\n",
    "    print(V)\n",
    "    #Do the correct estimations\n",
    "    EStar = E - 1.04*E/math.sqrt(m)\n",
    "\n",
    "    return EStar\n",
    "\n",
    "def splitElement(e):\n",
    "    split = e.split()\n",
    "    ip = split[0]\n",
    "    domain = split[1]\n",
    "    return ip, domain\n",
    "\n",
    "web_traffic_stream = stream(STREAM_SIZE)\n",
    "ds = buildHyperLogLog(web_traffic_stream, STREAM_SIZE, True, False,m)\n",
    "print(ds)\n",
    "hm = getHarmonicMean(ds)\n",
    "print(\"Harmonic mean: \" + str(hm))\n",
    "E = getEstimate(hm, ds, m)\n",
    "print(\"Estimate: \" + str(E))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Count min sketch\n",
    "\n",
    "d = 64\n",
    "w = 64\n",
    "def createM(d, w): \n",
    "    table = np.zeros([d, w])\n",
    "    return table\n",
    "\n",
    "def generateSeeds(d, w):\n",
    "    seeds = np.random.randint(w, size = d)\n",
    "    return seeds\n",
    "\n",
    "\n",
    "def increment(seeds, key, table, d, w):\n",
    "    for i in range(0, d):\n",
    "        index = mmh3.hash(key, seeds[i]) % w\n",
    "        table[i, index] = table[i, index]+1 \n",
    "    return table\n",
    "\n",
    "M = createM(d, w)\n",
    "seeds = generateSeeds(d,w)\n",
    "web_traffic_stream = stream(STREAM_SIZE)\n",
    "for e in web_traffic_stream:\n",
    "    increment(seeds,e,M,d,w)\n",
    "    \n",
    "def estimateResult(seeds, table, key, d, w):\n",
    "        min_est = 100000\n",
    "        for i in range(0, d):\n",
    "            index = mmh3.hash(key, seeds[i]) % w\n",
    "            #print(\"index\" + str(index))\n",
    "            #print(\"value\" + str(table[i, index]))\n",
    "            if table[i, index] < min_est:\n",
    "                min_est = table[i, index]\n",
    "        return min_est\n",
    "\n",
    "def init_countMinSketchIp(d, w, seed):\n",
    "    web_traffic_stream = stream(STREAM_SIZE)\n",
    "    M = createM(d, w)\n",
    "    \n",
    "    for e in web_traffic_stream:\n",
    "        split = e.split()\n",
    "        ip = split[0]\n",
    "        domain = split[1]\n",
    "        M = increment(seed,ip,M,d,w)\n",
    "    return M\n",
    "\n",
    "def init_countMinSketchDomain(d, w, seed):\n",
    "    web_traffic_stream = stream(STREAM_SIZE)\n",
    "    M = createM(d, w)\n",
    "\n",
    "    for e in web_traffic_stream:\n",
    "        split = e.split()\n",
    "        ip = split[0]\n",
    "        domain = split[1]\n",
    "        increment(seed,domain,M,d,w)\n",
    "    return M\n",
    "\n",
    "def countIp_countMinSketch(seed, M, targetIp, d, w):\n",
    "    return (estimateResult(seed, M, targetIp, d,w))\n",
    "\n",
    "def countDomain_countMinSketch(seed, M, targetDomain, d, w):\n",
    "    return (estimateResult(seed, M, targetDomain, d,w))\n",
    "\n",
    "def countAllDomain(seed, M, targetDomain, d, w):\n",
    "    web_traffic_stream = stream(STREAM_SIZE)\n",
    "    for e in web_traffic_stream:\n",
    "        print(estimateResult(seed, M, targetDomain, d,w))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count ip: 8.0\n",
      "Count domain: 281.0\n",
      "Count ip2: 9.0\n",
      "Count domain2: 510.0\n"
     ]
    }
   ],
   "source": [
    "seed = generateSeeds(d,w)\n",
    "M_ip = init_countMinSketchIp(d,w, seed)\n",
    "M_domain = init_countMinSketchDomain(d,w, seed)\n",
    "\n",
    "\n",
    "web_traffic_stream = stream(STREAM_SIZE)\n",
    "e = next(web_traffic_stream).split() \n",
    "targetIp = e[0]\n",
    "targetDomain = e[1]\n",
    "\n",
    "print(\"Count ip: \" + str(countIp_countMinSketch(seed, M_ip, targetIp, d, w)))\n",
    "print(\"Count domain: \" + str(countDomain_countMinSketch(seed, M_domain, targetDomain, d, w)))\n",
    "\n",
    "e2 = next(web_traffic_stream).split() \n",
    "targetIp2 = e2[0]\n",
    "targetDomain2 = e2[1]\n",
    "\n",
    "print(\"Count ip2: \" + str(countIp_countMinSketch(seed, M_ip, targetIp2, d, w)))\n",
    "print(\"Count domain2: \" + str(countDomain_countMinSketch(seed, M_domain, targetDomain2, d, w)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count python.org: 281.0\n"
     ]
    }
   ],
   "source": [
    "seed = generateSeeds(d,w)\n",
    "M = init_countMinSketchDomain(d, w, seed)\n",
    "\n",
    "web_traffic_stream = stream(STREAM_SIZE)\n",
    "\n",
    "targetDomain3 = 'python.org'\n",
    "print(\"Count \" + targetDomain3 +\": \" + str(countDomain_countMinSketch(seed, M, targetDomain3, d, w)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmh3\n",
    "import math\n",
    "\n",
    "\n",
    "class HyperLogLog: \n",
    "    def __init__(self):\n",
    "        self._part = 10\n",
    "        self._m = 2**self._part\n",
    "        self._alpha = 0.7213/(1+1.079/self._m)\n",
    "        self._M = [0 for i in range(0,self._m)]\n",
    "\n",
    "    def add(self, elem):\n",
    "        x = mmh3.hash(str(elem), signed=False)\n",
    "        binary = '{0:032b}'.format(x)\n",
    "        #part = int(math.log(64, 2))\n",
    "        upperpart = binary[:self._part]\n",
    "        lowerpart = binary[self._part:]\n",
    "        j = int(upperpart,2)\n",
    "\n",
    "        self._M[j] = max(self._M[j], len(lowerpart) - (int(lowerpart,2).bit_length()+1))\n",
    "\n",
    "        pass\n",
    "    \n",
    "    def hashElement(element):\n",
    "        # mmh3 64 outputs a 128 bit hash split in to two 64 bit outputs. \n",
    "        #For this purpose returning one of them will be sufficient\n",
    "        a,b = mmh3.hash64(str(element), signed=False)\n",
    "        return a\n",
    "\n",
    "    def estimate(self):\n",
    "        E = self._alpha*self._m**2*(sum([2**-number for number in self._M])**-1)\n",
    "        V = self._M.count(0)\n",
    "        \n",
    "        if E <= (5/2)*self._m:\n",
    "            if V != 0:\n",
    "                EStar = self.LinearCounting(V)*2\n",
    "            else:\n",
    "                EStar = E\n",
    "        elif E <= (1/30)*pow(2,32):\n",
    "            EStar = E\n",
    "        else: \n",
    "            EStar = -pow(2^32)*math.log2(1-E/pow(2,32))\n",
    "        \n",
    "        return EStar\n",
    "    \n",
    "    def LinearCounting(self, V):\n",
    "        return self._m*math.log2(self._m/V)\n",
    "    \n",
    "    def Merge(self, other):\n",
    "        res = HyperLogLog()\n",
    "        res._M = [max(self._M[i],other._M[i]) for i in range(0,self._m)]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "HLLDomain = HyperLogLog()\n",
    "HLLIp = HyperLogLog()\n",
    "web_traffic_stream = stream(STREAM_SIZE)\n",
    "\n",
    "for e in web_traffic_stream:\n",
    "    ip, domain = splitElement(e)\n",
    "    HLLDomain.add(domain)\n",
    "    HLLIp.add(ip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729.3825233413639"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HLL.estimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678.1235522227261"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HLLIp.estimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.776423039751338"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HLLDomain.estimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
